import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository } from 'typeorm';
import { Keyword } from '../../database/entities/keyword.entity';
import { KeywordCollectionLogs, CollectionType } from '../../database/entities/keyword-collection-logs.entity';
import { ScrapeKeywordsDto } from './dto/scraping.dto';
import { BrowserPoolService } from '../../common/services/browser-pool.service';
import { AppConfigService } from '../../config/app.config';
import { SCRAPING_DEFAULTS, SEARCH_VOLUME } from '../../constants/scraping.constants';

@Injectable()
export class ScrapingService {
  constructor(
    @InjectRepository(Keyword)
    private keywordRepository: Repository<Keyword>,
    @InjectRepository(KeywordCollectionLogs)
    private keywordCollectionLogsRepository: Repository<KeywordCollectionLogs>,
    private browserPoolService: BrowserPoolService,
    private appConfig: AppConfigService,
  ) {}

  async scrapeKeywords(scrapeDto: ScrapeKeywordsDto) {
    const startTime = Date.now();
    console.log(`ğŸ•·ï¸ í‚¤ì›Œë“œ ìŠ¤í¬ë˜í•‘ ì‹œì‘: ${scrapeDto.query}`);

    try {
      const { 
        query, 
        types = ['related_search'], 
        maxResults = this.appConfig.scrapingMaxResults 
      } = scrapeDto;
      
      // ì‹¤ì œ Playwright ê¸°ë°˜ ìŠ¤í¬ë˜í•‘ ìˆ˜í–‰ (ê°œì„ ëœ ì‘ë‹µ êµ¬ì¡°)
      const scrapingResult = await this.performRealScraping(query, types, maxResults);
      
      // ìˆ˜ì§‘ëœ í‚¤ì›Œë“œë“¤ì„ ë¡œê·¸ì— ì €ì¥
      await this.saveCollectionLogs(query, scrapingResult.keywords);
      
      const executionTime = (Date.now() - startTime) / 1000;
      
      // ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ê³„ì‚°
      const categories = scrapingResult.keywords.reduce((acc, keyword) => {
        acc[keyword.category] = (acc[keyword.category] || 0) + 1;
        return acc;
      }, {} as { [key: string]: number });

      console.log(`âœ… í‚¤ì›Œë“œ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: ${scrapingResult.keywords.length}ê°œ, ${executionTime}ì´ˆ`);

      return {
        query,
        totalKeywords: scrapingResult.keywords.length,
        executionTime,
        categories,
        keywords: scrapingResult.keywords,
        collectionDetails: scrapingResult.collectionDetails, // ìˆ˜ì§‘ ìƒì„¸ ì •ë³´ ì¶”ê°€
      };
    } catch (error) {
      console.error('âŒ ScrapingService.scrapeKeywords ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  async getCollectionLogs(query?: string, page = 1, limit = 20) {
    try {
      const queryBuilder = this.keywordCollectionLogsRepository
        .createQueryBuilder('log')
        .orderBy('log.collectedAt', 'DESC');

      if (query) {
        queryBuilder.where('log.baseQuery LIKE :query OR log.collectedKeyword LIKE :query', {
          query: `%${query}%`,
        });
      }

      const [logs, total] = await queryBuilder
        .skip((page - 1) * limit)
        .take(limit)
        .getManyAndCount();

      return {
        logs,
        total,
        page,
        limit,
      };
    } catch (error) {
      console.error('âŒ ScrapingService.getCollectionLogs ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  async getScrapingStats(days = 7) {
    try {
      const startDate = new Date();
      startDate.setDate(startDate.getDate() - days);

      const stats = await this.keywordCollectionLogsRepository
        .createQueryBuilder('log')
        .select([
          'DATE(log.collectedAt) as date',
          'log.collectionType as type',
          'COUNT(*) as count',
        ])
        .where('log.collectedAt >= :startDate', { startDate })
        .groupBy('DATE(log.collectedAt), log.collectionType')
        .orderBy('date', 'DESC')
        .getRawMany();

      // ì¼ë³„ í†µê³„ ì§‘ê³„
      const dailyStats = stats.reduce((acc, stat) => {
        const date = stat.date;
        if (!acc[date]) {
          acc[date] = { date, total: 0, types: {} };
        }
        acc[date].types[stat.type] = parseInt(stat.count);
        acc[date].total += parseInt(stat.count);
        return acc;
      }, {} as any);

      // íƒ€ì…ë³„ ì´ í†µê³„
      const typeStats = stats.reduce((acc, stat) => {
        acc[stat.type] = (acc[stat.type] || 0) + parseInt(stat.count);
        return acc;
      }, {} as any);

      return {
        period: `ìµœê·¼ ${days}ì¼`,
        dailyStats: Object.values(dailyStats),
        typeStats,
        totalKeywords: Object.values(typeStats).reduce((sum: number, count: number) => sum + count, 0),
      };
    } catch (error) {
      console.error('âŒ ScrapingService.getScrapingStats ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  private async performRealScraping(query: string, types: string[], maxResults: number) {
    const { NaverScraper } = await import('./scraper/naver-scraper');
    const scraper = new NaverScraper(this.browserPoolService);
    
    try {
      await scraper.initialize();
      
      // ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ìˆ˜í–‰ (ê°œì„ ëœ ì‘ë‹µ êµ¬ì¡°)
      const scrapingResult = await scraper.scrapeAllKeywords(query, types);
      
      // ê°œìˆ˜ ì œí•œ ì—†ì´ ëª¨ë“  í‚¤ì›Œë“œ ì‚¬ìš©
      console.log(`ğŸ“Š ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: ì´ ${scrapingResult.keywords.length}ê°œ í‚¤ì›Œë“œ (ê°œìˆ˜ ì œí•œ ì—†ìŒ)`);
      
      // ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì¹´í…Œê³ ë¦¬ë³„ ì›ë³¸ ìˆœìœ„ ìœ ì§€)
      const formattedKeywords = scrapingResult.keywords.map((keyword) => ({
        keyword: keyword.keyword,
        category: keyword.category,
        rank: keyword.rank, // ìŠ¤í¬ë˜í¼ì—ì„œ ì„¤ì •í•œ ì›ë³¸ ìˆœìœ„ ìœ ì§€ (ì¹´í…Œê³ ë¦¬ë³„ ë…ë¦½ì )
        source: keyword.source,
        competition: keyword.competition || 'medium',
        similarity: keyword.similarity || 'medium',
      }));
      
      return {
        keywords: formattedKeywords,
        collectionDetails: scrapingResult.collectionDetails
      };
    } finally {
      await scraper.close();
    }
  }

  /**
   * ë¸Œë¼ìš°ì € í’€ ìƒíƒœ ì¡°íšŒ
   */
  async getBrowserPoolStatus() {
    return this.browserPoolService.getPoolStatus();
  }


  /**
   * í‚¤ì›Œë“œë¥¼ ì°¾ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤
   */
  private async findOrCreateKeyword(keywordText: string): Promise<Keyword> {
    let keyword = await this.keywordRepository.findOne({
      where: { keyword: keywordText }
    });

    if (!keyword) {
      keyword = this.keywordRepository.create({
        keyword: keywordText,
        status: 'active'
      });
      keyword = await this.keywordRepository.save(keyword);
      console.log(`ğŸ†• ìƒˆ í‚¤ì›Œë“œ ìƒì„±: ${keywordText} (ID: ${keyword.id})`);
    }

    return keyword;
  }

  private async saveCollectionLogs(baseQuery: string, keywords: any[]) {
    try {
      // ê¸°ì¤€ ì¿¼ë¦¬ í‚¤ì›Œë“œ ì°¾ê¸°/ìƒì„±
      const baseKeyword = await this.findOrCreateKeyword(baseQuery);

      // ìˆ˜ì§‘ëœ í‚¤ì›Œë“œë“¤ ì²˜ë¦¬
      const logs = [];
      for (const keyword of keywords) {
        const collectedKeyword = await this.findOrCreateKeyword(keyword.keyword);
        
        const log = this.keywordCollectionLogsRepository.create({
          baseQueryId: baseKeyword.id,
          collectedKeywordId: collectedKeyword.id,
          collectionType: keyword.category as CollectionType,
          rankPosition: keyword.rank,
        });
        
        logs.push(log);
      }

      await this.keywordCollectionLogsRepository.save(logs);
      console.log(`ğŸ“ ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: ${logs.length}ê°œ`);
    } catch (error) {
      console.error('âŒ ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:', error);
      // ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ
    }
  }
}
