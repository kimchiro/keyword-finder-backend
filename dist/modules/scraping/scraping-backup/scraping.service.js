"use strict";
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var __metadata = (this && this.__metadata) || function (k, v) {
    if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(k, v);
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.ScrapingService = void 0;
const common_1 = require("@nestjs/common");
const config_1 = require("@nestjs/config");
let ScrapingService = class ScrapingService {
    constructor(configService) {
        this.configService = configService;
    }
    async scrapeKeywords(scrapeDto) {
        const startTime = Date.now();
        console.log(`ğŸ•·ï¸ í‚¤ì›Œë“œ ìŠ¤í¬ë˜í•‘ ì‹œì‘: ${scrapeDto.query}`);
        try {
            const { query, types = ['related_search'], maxResults = 50 } = scrapeDto;
            const scrapingResult = await this.performRealScraping(query, types, maxResults);
            const executionTime = (Date.now() - startTime) / 1000;
            const categories = scrapingResult.keywords.reduce((acc, keyword) => {
                acc[keyword.category] = (acc[keyword.category] || 0) + 1;
                return acc;
            }, {});
            console.log(`âœ… í‚¤ì›Œë“œ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: ${scrapingResult.keywords.length}ê°œ, ${executionTime}ì´ˆ`);
            return {
                query,
                totalKeywords: scrapingResult.keywords.length,
                executionTime,
                categories,
                keywords: scrapingResult.keywords,
                collectionDetails: scrapingResult.collectionDetails,
            };
        }
        catch (error) {
            console.error('âŒ ScrapingService.scrapeKeywords ì˜¤ë¥˜:', error);
            throw error;
        }
    }
    async getCollectionLogs(query, page = 1, limit = 20) {
        try {
            const queryBuilder = this.keywordCollectionLogsRepository
                .createQueryBuilder('log')
                .orderBy('log.collectedAt', 'DESC');
            if (query) {
                queryBuilder.where('log.baseQuery LIKE :query OR log.collectedKeyword LIKE :query', {
                    query: `%${query}%`,
                });
            }
            const [logs, total] = await queryBuilder
                .skip((page - 1) * limit)
                .take(limit)
                .getManyAndCount();
            return {
                logs,
                total,
                page,
                limit,
            };
        }
        catch (error) {
            console.error('âŒ ScrapingService.getCollectionLogs ì˜¤ë¥˜:', error);
            throw error;
        }
    }
    async getScrapingStats(days = 7) {
        try {
            const startDate = new Date();
            startDate.setDate(startDate.getDate() - days);
            const stats = await this.keywordCollectionLogsRepository
                .createQueryBuilder('log')
                .select([
                'DATE(log.collectedAt) as date',
                'log.collectionType as type',
                'COUNT(*) as count',
            ])
                .where('log.collectedAt >= :startDate', { startDate })
                .groupBy('DATE(log.collectedAt), log.collectionType')
                .orderBy('date', 'DESC')
                .getRawMany();
            const dailyStats = stats.reduce((acc, stat) => {
                const date = stat.date;
                if (!acc[date]) {
                    acc[date] = { date, total: 0, types: {} };
                }
                acc[date].types[stat.type] = parseInt(stat.count);
                acc[date].total += parseInt(stat.count);
                return acc;
            }, {});
            const typeStats = stats.reduce((acc, stat) => {
                acc[stat.type] = (acc[stat.type] || 0) + parseInt(stat.count);
                return acc;
            }, {});
            return {
                period: `ìµœê·¼ ${days}ì¼`,
                dailyStats: Object.values(dailyStats),
                typeStats,
                totalKeywords: Object.values(typeStats).reduce((sum, count) => sum + count, 0),
            };
        }
        catch (error) {
            console.error('âŒ ScrapingService.getScrapingStats ì˜¤ë¥˜:', error);
            throw error;
        }
    }
    async performRealScraping(query, types, maxResults) {
        const { NaverScraper } = await Promise.resolve().then(() => require('./scraper/naver-scraper'));
        const scraper = new NaverScraper(this.browserPoolService);
        try {
            await scraper.initialize();
            const scrapingResult = await scraper.scrapeAllKeywords(query, types);
            console.log(`ğŸ“Š ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: ì´ ${scrapingResult.keywords.length}ê°œ í‚¤ì›Œë“œ (ê°œìˆ˜ ì œí•œ ì—†ìŒ)`);
            const formattedKeywords = scrapingResult.keywords.map((keyword) => ({
                keyword: keyword.keyword,
                category: keyword.category,
                rank: keyword.rank,
                source: keyword.source,
                competition: keyword.competition || 'medium',
                similarity: keyword.similarity || 'medium',
            }));
            return {
                keywords: formattedKeywords,
                collectionDetails: scrapingResult.collectionDetails
            };
        }
        finally {
            await scraper.close();
        }
    }
    async getBrowserPoolStatus() {
        return {
            status: 'disabled',
            message: 'ë¸Œë¼ìš°ì € í’€ ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤',
            timestamp: new Date().toISOString()
        };
    }
    async findOrCreateKeyword(keywordText) {
        console.log(`ğŸ†• í‚¤ì›Œë“œ ì²˜ë¦¬ (ì„ì‹œ): ${keywordText}`);
        return { id: Date.now(), keyword: keywordText, status: 'active' };
    }
    async saveCollectionLogs(baseQuery, keywords) {
        try {
            console.log(`ğŸ“ ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥ (ì„ì‹œ ë¹„í™œì„±í™”): ${keywords.length}ê°œ`);
        }
        catch (error) {
            console.error('âŒ ìˆ˜ì§‘ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:', error);
        }
    }
};
exports.ScrapingService = ScrapingService;
exports.ScrapingService = ScrapingService = __decorate([
    (0, common_1.Injectable)(),
    __metadata("design:paramtypes", [config_1.ConfigService])
], ScrapingService);
//# sourceMappingURL=scraping.service.js.map